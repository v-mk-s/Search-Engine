{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABw6iDUWkSTK",
    "outputId": "2a369c69-7575-40c4-cb37-26f80eacaa51"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/vladislavkruglikov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/vladislavkruglikov/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Yv-Ipap9hXLW",
    "outputId": "8faa26f6-1c74-4533-eb44-082f4573c5f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>2008-08-01T13:57:07Z</td>\n",
       "      <td>26</td>\n",
       "      <td>SQLStatement.execute() - multiple queries in o...</td>\n",
       "      <td>&lt;p&gt;I've written a database generation script i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>2008-08-01T14:41:24Z</td>\n",
       "      <td>144</td>\n",
       "      <td>Good branching and merging tutorials for Torto...</td>\n",
       "      <td>&lt;p&gt;Are there any really good tutorials explain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>2008-08-01T15:50:08Z</td>\n",
       "      <td>21</td>\n",
       "      <td>ASP.NET Site Maps</td>\n",
       "      <td>&lt;p&gt;Has anyone got experience creating &lt;strong&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180</td>\n",
       "      <td>2008-08-01T18:42:19Z</td>\n",
       "      <td>53</td>\n",
       "      <td>Function for creating color wheels</td>\n",
       "      <td>&lt;p&gt;This is something I've pseudo-solved many t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260</td>\n",
       "      <td>2008-08-01T23:22:08Z</td>\n",
       "      <td>49</td>\n",
       "      <td>Adding scripting functionality to .NET applica...</td>\n",
       "      <td>&lt;p&gt;I have a little game written in C#. It uses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>162650</td>\n",
       "      <td>2008-10-02T14:38:16Z</td>\n",
       "      <td>4</td>\n",
       "      <td>How do I detect \"Easter Egg\" mode in my Palm O...</td>\n",
       "      <td>&lt;p&gt;Since the early days, Palm OS has had a spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>162680</td>\n",
       "      <td>2008-10-02T14:42:33Z</td>\n",
       "      <td>14</td>\n",
       "      <td>The value of hobby game development</td>\n",
       "      <td>&lt;p&gt;Does attempting to develop some sort of gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>162730</td>\n",
       "      <td>2008-10-02T14:49:46Z</td>\n",
       "      <td>6</td>\n",
       "      <td>Rendered pIxel width data for each character i...</td>\n",
       "      <td>&lt;p&gt;I have a table column that needs to be limi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>162810</td>\n",
       "      <td>2008-10-02T15:00:21Z</td>\n",
       "      <td>26</td>\n",
       "      <td>How do you log the machine name via log4net?</td>\n",
       "      <td>&lt;p&gt;I am using Log4Net with the AdoNetAppender ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>162940</td>\n",
       "      <td>2008-10-02T15:19:16Z</td>\n",
       "      <td>3</td>\n",
       "      <td>Would it be possible to use web services from ...</td>\n",
       "      <td>&lt;p&gt;We have some COBOL programs in our financia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id          CreationDate  Score  \\\n",
       "0         80  2008-08-01T13:57:07Z     26   \n",
       "1         90  2008-08-01T14:41:24Z    144   \n",
       "2        120  2008-08-01T15:50:08Z     21   \n",
       "3        180  2008-08-01T18:42:19Z     53   \n",
       "4        260  2008-08-01T23:22:08Z     49   \n",
       "...      ...                   ...    ...   \n",
       "1995  162650  2008-10-02T14:38:16Z      4   \n",
       "1996  162680  2008-10-02T14:42:33Z     14   \n",
       "1997  162730  2008-10-02T14:49:46Z      6   \n",
       "1998  162810  2008-10-02T15:00:21Z     26   \n",
       "1999  162940  2008-10-02T15:19:16Z      3   \n",
       "\n",
       "                                                  Title  \\\n",
       "0     SQLStatement.execute() - multiple queries in o...   \n",
       "1     Good branching and merging tutorials for Torto...   \n",
       "2                                     ASP.NET Site Maps   \n",
       "3                    Function for creating color wheels   \n",
       "4     Adding scripting functionality to .NET applica...   \n",
       "...                                                 ...   \n",
       "1995  How do I detect \"Easter Egg\" mode in my Palm O...   \n",
       "1996                The value of hobby game development   \n",
       "1997  Rendered pIxel width data for each character i...   \n",
       "1998       How do you log the machine name via log4net?   \n",
       "1999  Would it be possible to use web services from ...   \n",
       "\n",
       "                                                   Body  \n",
       "0     <p>I've written a database generation script i...  \n",
       "1     <p>Are there any really good tutorials explain...  \n",
       "2     <p>Has anyone got experience creating <strong>...  \n",
       "3     <p>This is something I've pseudo-solved many t...  \n",
       "4     <p>I have a little game written in C#. It uses...  \n",
       "...                                                 ...  \n",
       "1995  <p>Since the early days, Palm OS has had a spe...  \n",
       "1996  <p>Does attempting to develop some sort of gam...  \n",
       "1997  <p>I have a table column that needs to be limi...  \n",
       "1998  <p>I am using Log4Net with the AdoNetAppender ...  \n",
       "1999  <p>We have some COBOL programs in our financia...  \n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/Questions.csv', encoding=\"ISO-8859-1\", nrows=2000,\n",
    "                 usecols=['Id', 'Title', 'Body', 'CreationDate', 'Score'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRopbpn8o6p-"
   },
   "source": [
    "## Remove stopwords\n",
    "\n",
    "Function to remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GrDX2y7Ro8Tp",
    "outputId": "75a8623b-ad22-4a4a-9344-6576a7cfc1f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vladislavkruglikov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/vladislavkruglikov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def lower_remove_punctuation(text):\n",
    "    text = text.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text_tokens = tokenizer.tokenize(text)\n",
    "    return ' '.join(text_tokens)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text_tokens = word_tokenize(text)\n",
    "    tokens_without_sw = [w for w in text_tokens if not w in stopwords and w.isalnum()]\n",
    "    return ' '.join(tokens_without_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqiZK7g5pvHB"
   },
   "source": [
    "## Lemmatize\n",
    "\n",
    "Function to lemmatize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "q803nX9fpyjd"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    text_tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(w) for w in text_tokens]\n",
    "    return ' '.join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aBV4WgYnq9OI"
   },
   "source": [
    "## Title preprocessing\n",
    "\n",
    "Remoing stop words, and apply lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ckSLsUc2q_W3"
   },
   "outputs": [],
   "source": [
    "title = df['Title']\n",
    "\n",
    "df['Title preprocessed'] = title.apply(lower_remove_punctuation).apply(remove_stop_words).apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DMAzQT6r5Yy"
   },
   "source": [
    "## Body preprocessing\n",
    "\n",
    "Since ```Body``` contains many code fragments and we don't want to use code fragments in search we need to get rid of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TyUfmT_0r714"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "body = df['Body']\n",
    "\n",
    "def remove_spaces(text):\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "def remove_code(text):\n",
    "    # remove code part\n",
    "    text = re.sub('<pre>.*<\\/pre>', '', text)\n",
    "    # remove tags\n",
    "    text = re.sub('<a.*?>', '', text)\n",
    "    text = re.sub('</a>', '', text)\n",
    "    text = re.sub('<code>', '', text)\n",
    "    text = re.sub('</code>', '', text)\n",
    "    text = re.sub('<p>', '', text)\n",
    "    text = re.sub('</p>', '', text)\n",
    "    return text\n",
    "\n",
    "df['Body preprocessed'] = body.apply(lower_remove_punctuation).apply(remove_spaces).apply(remove_code).apply(remove_stop_words).apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCalXEkIyX71"
   },
   "source": [
    "## Fit TF-IDF title vectorizer\n",
    "\n",
    "Fit TF-IDF vectorizer for title column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hB03fzWWyacd"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pickle\n",
    "\n",
    "tfidf_title_vectorizer = TfidfVectorizer()\n",
    "\n",
    "title_preprocessed = df['Title preprocessed']\n",
    "\n",
    "tfidf_title_vectorizer.fit(title_preprocessed)\n",
    "\n",
    "pickle.dump(tfidf_title_vectorizer, open('data/tfidf_title_vectorizer.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYpNtjg2ykz6"
   },
   "source": [
    "## Extract keywords from TF-IDF title vectorizer\n",
    "\n",
    "Get top 10 words with highest TF-IDF from each title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kKwQ42iJyonC"
   },
   "outputs": [],
   "source": [
    "def get_top_tfidf_words(sentence, tfidf_vectorizer, n=5):\n",
    "    terms = tfidf_vectorizer.get_feature_names()\n",
    "    sums = tfidf_vectorizer.transform([sentence]).sum(axis=0)\n",
    "    data = []\n",
    "    for col, term in enumerate(terms):\n",
    "        if sums[0, col] > 0:\n",
    "            data.append((term, sums[0, col]))\n",
    "    data.sort(key=lambda x: -x[1])\n",
    "    return ' '.join([i[0] for i in data[:n]])\n",
    "\n",
    "df['Title preprocessed top 10 keywords'] = title_preprocessed.apply(lambda text: get_top_tfidf_words(text, tfidf_title_vectorizer, n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsLE1ZmQzfWu"
   },
   "source": [
    "## Fit TF-IDF body vectorizer\n",
    "\n",
    "Fit TF-IDF vectorizer for ```body``` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nZLzXfx_zhRk"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_body_vectorizer = TfidfVectorizer()\n",
    "\n",
    "body_preprocessed = df['Body preprocessed']\n",
    "\n",
    "tfidf_body_vectorizer.fit(body_preprocessed)\n",
    "\n",
    "pickle.dump(tfidf_body_vectorizer, open('data/tfidf_body_vectorizer.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2RtCtarzZ5b"
   },
   "source": [
    "## Extract keywords from TF-IDF body vectorizer\n",
    "\n",
    "Get top 30 words with highest TF-IDF from each body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xpLSIdWtzdDf"
   },
   "outputs": [],
   "source": [
    "df['Body preprocessed top 30 keywords'] = body_preprocessed.apply(lambda text: get_top_tfidf_words(text, tfidf_body_vectorizer, n=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loXMf148GdtB"
   },
   "source": [
    "## Get date score\n",
    "\n",
    "The newest questions have higher score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RHjDCW3VGdUT"
   },
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.DatetimeIndex(df.CreationDate).asi8\n",
    "\n",
    "date_min = df.timestamp.min()\n",
    "date_max = df.timestamp.max()\n",
    "\n",
    "def date_score(date):\n",
    "    return 1 + (date - date_min) / (date_max - date_min)\n",
    "\n",
    "df['Date score'] = df.timestamp.apply(date_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKzs008oG8Y8"
   },
   "source": [
    "## Get Vote score\n",
    "\n",
    "The questions with more votes are probably better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Pb_5xiGyG-SX"
   },
   "outputs": [],
   "source": [
    "votes = df['Score']\n",
    "\n",
    "votes_min = votes.min()\n",
    "votes_max = votes.max()\n",
    "\n",
    "def votes_score(votes):\n",
    "    return 1 + (votes - votes_min) / (votes_max - votes_min)\n",
    "\n",
    "df['Votes score'] = df['Score'].apply(votes_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzB0nfem6woQ"
   },
   "source": [
    "## Calculate TF-IDF vectors for title preprocessed top 10 keywords\n",
    "\n",
    "Will use this to calculate distance between query TF-IDF vector and database documents TF-IDF vectors to find the most similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2jWdZn2h62oD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df['Title preprocessed top 10 keywords TF-IDF vector'] = df['Title preprocessed top 10 keywords'].apply(lambda x: tfidf_title_vectorizer.transform([x]))\n",
    "\n",
    "def calculate_distance(vec1, vec2):\n",
    "    cosine_similarities = cosine_similarity(vec1.reshape(1, -1), vec2.reshape(1, -1))\n",
    "    return cosine_similarities[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6LUeMcf9CGS",
    "outputId": "90890792-3f06-4dbe-914c-fa1763a85fe4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4012645297636559"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For example\n",
    "\n",
    "query = \"multiple query one sql\"\n",
    "\n",
    "calculate_distance(df['Title preprocessed top 10 keywords TF-IDF vector'][0], tfidf_title_vectorizer.transform([query]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3JPPD-MEz2B"
   },
   "source": [
    "## Calculate TF-IDF vectors for body preprocessed top 30 keywords\n",
    "\n",
    "Will use this to calculate distance between query TF-IDF vector and database documents TF-IDF vectors to find the most similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "50b7zGjvE31-"
   },
   "outputs": [],
   "source": [
    "df['Body preprocessed top 30 keywords TF-IDF vector'] = df['Body preprocessed top 30 keywords'].apply(lambda x: tfidf_body_vectorizer.transform([x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RuzwF39xDRJA"
   },
   "source": [
    "## Build Inverted Index for title\n",
    "\n",
    "Function for creating inverted index to allow us do the first stage of search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "VEYKxkt3DSGd"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def build_inverted_index(data: list) -> list:\n",
    "    inverted_index = defaultdict(list)\n",
    "    rows = len(data)\n",
    "    for idx in range(1, rows):\n",
    "        sample = df.iloc[idx]\n",
    "        for word in set(data[idx].split()):\n",
    "            inverted_index[word].append(sample.Id)\n",
    "    return inverted_index\n",
    "\n",
    "title_inverted_index = build_inverted_index(df['Title preprocessed top 10 keywords'])\n",
    "pickle.dump(title_inverted_index, open('data/title_inverted_index.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrSxpddCDVny"
   },
   "source": [
    "## Build Inverted Index for body\n",
    "\n",
    "Create different inverted index for body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "JFTAAzBRDWcC"
   },
   "outputs": [],
   "source": [
    "body_inverted_index = build_inverted_index(df['Body preprocessed top 30 keywords'])\n",
    "pickle.dump(body_inverted_index, open('data/body_inverted_index.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qV0y8xMyICli"
   },
   "source": [
    "## Clear not needed cols\n",
    "\n",
    "Save space by removing columns that we don't need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "WxE3715eIEAK"
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['CreationDate', 'timestamp', 'Score', 'Title preprocessed', 'Body preprocessed',\n",
    "                 'Title preprocessed top 10 keywords', 'Body preprocessed top 30 keywords'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2PEKGXr4Tlm"
   },
   "source": [
    "## Look at the final dataset\n",
    "\n",
    "Our dataset after all transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 728
    },
    "id": "z-HK9-a-j5Fo",
    "outputId": "fd09367f-ae8a-4e28-85a6-2d80ae28e922"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Date score</th>\n",
       "      <th>Votes score</th>\n",
       "      <th>Title preprocessed top 10 keywords TF-IDF vector</th>\n",
       "      <th>Body preprocessed top 30 keywords TF-IDF vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>SQLStatement.execute() - multiple queries in o...</td>\n",
       "      <td>&lt;p&gt;I've written a database generation script i...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.008020</td>\n",
       "      <td>(0, 2522)\\t0.44092916579466235\\n  (0, 2502)\\...</td>\n",
       "      <td>(0, 12280)\\t0.14965085848996112\\n  (0, 11933...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>Good branching and merging tutorials for Torto...</td>\n",
       "      <td>&lt;p&gt;Are there any really good tutorials explain...</td>\n",
       "      <td>1.000496</td>\n",
       "      <td>1.040653</td>\n",
       "      <td>(0, 2766)\\t0.44673955305001606\\n  (0, 2718)\\...</td>\n",
       "      <td>(0, 11527)\\t0.20752904045981943\\n  (0, 11362...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>ASP.NET Site Maps</td>\n",
       "      <td>&lt;p&gt;Has anyone got experience creating &lt;strong&gt;...</td>\n",
       "      <td>1.001265</td>\n",
       "      <td>1.006637</td>\n",
       "      <td>(0, 2420)\\t0.5700230506438555\\n  (0, 1720)\\t...</td>\n",
       "      <td>(0, 12463)\\t0.1584405084728794\\n  (0, 12366)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180</td>\n",
       "      <td>Function for creating color wheels</td>\n",
       "      <td>&lt;p&gt;This is something I've pseudo-solved many t...</td>\n",
       "      <td>1.003192</td>\n",
       "      <td>1.015487</td>\n",
       "      <td>(0, 2935)\\t0.5985527917055988\\n  (0, 1066)\\t...</td>\n",
       "      <td>(0, 12168)\\t0.1135941802842356\\n  (0, 11261)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260</td>\n",
       "      <td>Adding scripting functionality to .NET applica...</td>\n",
       "      <td>&lt;p&gt;I have a little game written in C#. It uses...</td>\n",
       "      <td>1.006323</td>\n",
       "      <td>1.014381</td>\n",
       "      <td>(0, 2324)\\t0.5579416322563129\\n  (0, 1720)\\t...</td>\n",
       "      <td>(0, 11407)\\t0.24273624456573292\\n  (0, 10340...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>162650</td>\n",
       "      <td>How do I detect \"Easter Egg\" mode in my Palm O...</td>\n",
       "      <td>&lt;p&gt;Since the early days, Palm OS has had a spe...</td>\n",
       "      <td>1.999541</td>\n",
       "      <td>1.001936</td>\n",
       "      <td>(0, 1866)\\t0.46452687942678234\\n  (0, 1646)\\...</td>\n",
       "      <td>(0, 11523)\\t0.1736861396348638\\n  (0, 11459)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>162680</td>\n",
       "      <td>The value of hobby game development</td>\n",
       "      <td>&lt;p&gt;Does attempting to develop some sort of gam...</td>\n",
       "      <td>1.999589</td>\n",
       "      <td>1.004701</td>\n",
       "      <td>(0, 2848)\\t0.3918436193550127\\n  (0, 1198)\\t...</td>\n",
       "      <td>(0, 12153)\\t0.1868131460456036\\n  (0, 11918)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>162730</td>\n",
       "      <td>Rendered pIxel width data for each character i...</td>\n",
       "      <td>&lt;p&gt;I have a table column that needs to be limi...</td>\n",
       "      <td>1.999670</td>\n",
       "      <td>1.002489</td>\n",
       "      <td>(0, 2944)\\t0.4610126117448486\\n  (0, 2180)\\t...</td>\n",
       "      <td>(0, 12274)\\t0.16958930694063776\\n  (0, 12271...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>162810</td>\n",
       "      <td>How do you log the machine name via log4net?</td>\n",
       "      <td>&lt;p&gt;I am using Log4Net with the AdoNetAppender ...</td>\n",
       "      <td>1.999788</td>\n",
       "      <td>1.008020</td>\n",
       "      <td>(0, 2876)\\t0.43840683427196825\\n  (0, 1701)\\...</td>\n",
       "      <td>(0, 12168)\\t0.08214542688555762\\n  (0, 12140...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>162940</td>\n",
       "      <td>Would it be possible to use web services from ...</td>\n",
       "      <td>&lt;p&gt;We have some COBOL programs in our financia...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.001659</td>\n",
       "      <td>(0, 2976)\\t0.45449768901884535\\n  (0, 2365)\\...</td>\n",
       "      <td>(0, 12409)\\t0.23124226187311975\\n  (0, 12174...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id                                              Title  \\\n",
       "0         80  SQLStatement.execute() - multiple queries in o...   \n",
       "1         90  Good branching and merging tutorials for Torto...   \n",
       "2        120                                  ASP.NET Site Maps   \n",
       "3        180                 Function for creating color wheels   \n",
       "4        260  Adding scripting functionality to .NET applica...   \n",
       "...      ...                                                ...   \n",
       "1995  162650  How do I detect \"Easter Egg\" mode in my Palm O...   \n",
       "1996  162680                The value of hobby game development   \n",
       "1997  162730  Rendered pIxel width data for each character i...   \n",
       "1998  162810       How do you log the machine name via log4net?   \n",
       "1999  162940  Would it be possible to use web services from ...   \n",
       "\n",
       "                                                   Body  Date score  \\\n",
       "0     <p>I've written a database generation script i...    1.000000   \n",
       "1     <p>Are there any really good tutorials explain...    1.000496   \n",
       "2     <p>Has anyone got experience creating <strong>...    1.001265   \n",
       "3     <p>This is something I've pseudo-solved many t...    1.003192   \n",
       "4     <p>I have a little game written in C#. It uses...    1.006323   \n",
       "...                                                 ...         ...   \n",
       "1995  <p>Since the early days, Palm OS has had a spe...    1.999541   \n",
       "1996  <p>Does attempting to develop some sort of gam...    1.999589   \n",
       "1997  <p>I have a table column that needs to be limi...    1.999670   \n",
       "1998  <p>I am using Log4Net with the AdoNetAppender ...    1.999788   \n",
       "1999  <p>We have some COBOL programs in our financia...    2.000000   \n",
       "\n",
       "      Votes score   Title preprocessed top 10 keywords TF-IDF vector  \\\n",
       "0        1.008020    (0, 2522)\\t0.44092916579466235\\n  (0, 2502)\\...   \n",
       "1        1.040653    (0, 2766)\\t0.44673955305001606\\n  (0, 2718)\\...   \n",
       "2        1.006637    (0, 2420)\\t0.5700230506438555\\n  (0, 1720)\\t...   \n",
       "3        1.015487    (0, 2935)\\t0.5985527917055988\\n  (0, 1066)\\t...   \n",
       "4        1.014381    (0, 2324)\\t0.5579416322563129\\n  (0, 1720)\\t...   \n",
       "...           ...                                                ...   \n",
       "1995     1.001936    (0, 1866)\\t0.46452687942678234\\n  (0, 1646)\\...   \n",
       "1996     1.004701    (0, 2848)\\t0.3918436193550127\\n  (0, 1198)\\t...   \n",
       "1997     1.002489    (0, 2944)\\t0.4610126117448486\\n  (0, 2180)\\t...   \n",
       "1998     1.008020    (0, 2876)\\t0.43840683427196825\\n  (0, 1701)\\...   \n",
       "1999     1.001659    (0, 2976)\\t0.45449768901884535\\n  (0, 2365)\\...   \n",
       "\n",
       "        Body preprocessed top 30 keywords TF-IDF vector  \n",
       "0       (0, 12280)\\t0.14965085848996112\\n  (0, 11933...  \n",
       "1       (0, 11527)\\t0.20752904045981943\\n  (0, 11362...  \n",
       "2       (0, 12463)\\t0.1584405084728794\\n  (0, 12366)...  \n",
       "3       (0, 12168)\\t0.1135941802842356\\n  (0, 11261)...  \n",
       "4       (0, 11407)\\t0.24273624456573292\\n  (0, 10340...  \n",
       "...                                                 ...  \n",
       "1995    (0, 11523)\\t0.1736861396348638\\n  (0, 11459)...  \n",
       "1996    (0, 12153)\\t0.1868131460456036\\n  (0, 11918)...  \n",
       "1997    (0, 12274)\\t0.16958930694063776\\n  (0, 12271...  \n",
       "1998    (0, 12168)\\t0.08214542688555762\\n  (0, 12140...  \n",
       "1999    (0, 12409)\\t0.23124226187311975\\n  (0, 12174...  \n",
       "\n",
       "[2000 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhxZ2BVIC3dy"
   },
   "source": [
    "## Save preprocessed dataset\n",
    "\n",
    "Save dataset to pickle file, it's better to use pickle because it allows us to save ```TF-IDF vector``` scipy format of column, because pandas will force it to be string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "fV7qSWwqCv87"
   },
   "outputs": [],
   "source": [
    "pickle.dump(df, open('data/Preprocessed Questions.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}